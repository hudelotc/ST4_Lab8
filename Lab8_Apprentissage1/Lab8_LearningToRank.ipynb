{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H8PfrcnQsHih"
   },
   "source": [
    "# Recherche d'Information et traitement de données massives\n",
    "\n",
    "## Lab 8 : Apprentissage et Recherche d'information - Learning to Rank\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif de cette séance est la mise en oeuvre des approches pour la recherche d'information vue comme un problème d'apprentissage d'une fonction d'ordonnancement.\n",
    "\n",
    "En particulier, dans ce premier TP vous mettrez en oeuvre l'**approche par point** modélisée comme un problème de regression. \n",
    "\n",
    "<img src=\"./Figures/pairewise.gif\" width=\"500\" height=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A4GevBvasHik"
   },
   "source": [
    "### Prise en main des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2dJrPdYlsHil"
   },
   "source": [
    "Nous travaillerons à partir du jeu de données mis en place par Chris Manning et Pandu Nayak pour leur très bon [cours](http://web.stanford.edu/class/cs276/) de recherche d'information et qui est accessible dans le répertoire [Data/pa3-data](./Data/pa3-data). \n",
    "\n",
    "Ce jeu de données contient **un ensemble d'apprentissage** constitué de paires `(requête,document)` et pour chaque paire d'un ensemble d'informations utiles pour ordonnancer les documents. Les données sont aussi séparées en un ensemble d'apprentissage et en un ensemble de test.\n",
    "\n",
    "Plus précisemment, le répertoire [Data/pa3-data](./Data/pa3-data) contient :\n",
    "\n",
    "+ Le fichier [pa3.signal.train](Data/pa3-data/pa3.signal.train) qui contient 731 requêtes et pour chaque requête une liste d'au plus 10 documents renvoyés par un moteur de recherche connu. La description détaillée de ce fichier est donnée plus loin.\n",
    "\n",
    "+ Le fichier [pa3.rel.train](Data/pa3-data/pa3.rel.train) qui contient les jugements de pertinences donnés sous la forme d'un score de pertinence entre -1 et 3 pour chaque requête et chaque document associé à cette requête. Un extrait de ce fichier est donné ci-dessous.\n",
    "\n",
    "````\n",
    "======================================================================================\n",
    "query: stanford aoerc pool hours\n",
    "  url: http://events.stanford.edu/2014/February/18/ 0.0\n",
    "  url: http://events.stanford.edu/2014/February/6/ 0.0\n",
    "  url: http://events.stanford.edu/2014/March/13/ 0.0\n",
    "  url: http://events.stanford.edu/2014/March/3/ 0.0\n",
    "  url: http://med.stanford.edu/content/dam/sm/hip/documents/FreeFitnessWeek.pdf 0.0\n",
    "  url: http://web.stanford.edu/group/masters/pool.html 1.0\n",
    "  url: https://alumni.stanford.edu/get/page/perks/PoolAndGyms 1.5\n",
    "  url: https://cardinalrec.stanford.edu/facilities/aoerc/ 2.0\n",
    "  url: https://explorecourses.stanford.edu/search?view=catalog&filter-coursestatus-Active=on&page=0&catalog=&q=PE+128%3A+Swimming%3A+Beginning+I&collapse= 0.5\n",
    "  url: https://glo.stanford.edu/events/stanford-rec-open-house 0.5\n",
    "  \n",
    "======================================================================================\n",
    "````\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "L'extrait ci-dessus indique que pour la requête `stanford aoerc pool hours`, le document d'url `http://events.stanford.edu/2014/February/18/` a pour score de pertinence `0.0` et que celui d'url `https://alumni.stanford.edu/get/page/perks/PoolAndGyms` a pour score de pertinence `1.5`.\n",
    "\n",
    "\n",
    "Les fichiers [pa3.signal.train](Data/pa3-data/pa3.signal.train) et [pa3.rel.train](Data/pa3-data/pa3.rel.train) sont utilisés comme **ensemble d'apprentissage**.\n",
    "\n",
    "Le répertoire contient aussi deux fichiers qui seront utilisés comme **ensemble de test** :\n",
    "\n",
    "+ Le fichier [pa3.signal.dev](Data/pa3-data/pa3.signal.dev) qui contient 124 requêtes et pour chaque requête une liste d'au plus 10 documents renvoyés par un moteur de recherche connu.\n",
    "+ Le fichier [pa3.rel.dev](Data/pa3-data/pa3.signal.dev) qui contient les scores de pertinences pour les requêtes et les documents du fichier [pa3.signal.dev](Data/pa3-data/pa3.signal.dev).\n",
    "\n",
    "\n",
    "\n",
    "####  Description du fichier [pa3.signal.train](Data/pa3-data/pa3.signal.train)\n",
    "\n",
    "\n",
    "Le fichier [pa3.signal.train](Data/pa3-data/pa3.signal.train) contient pour un ensemble de requêtes, les documents retournés pour cette requête et un ensemble d'information pour chacun de ces documents que nous allons utiliser pour construire notre ensemble de fichiers caractéristiques.\n",
    "\n",
    "\n",
    "Le code ci-dessous permet d'afficher une partie du fichier [pa3.signal.train](Data/pa3-data/pa3.signal.train) et de visualiser l'information pour une requête donnée. Executez le.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dZqyHwOOsHim"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: stanford aoerc pool hours\n",
      "  url: http://events.stanford.edu/2014/February/18/\n",
      "    title: events at stanford tuesday february 18 2014\n",
      "    header: stanford university event calendar\n",
      "    header: teaching sex at stanford\n",
      "    header: rodin the complete stanford collection\n",
      "    header: stanford rec trx suspension training\n",
      "    header: memorial church open visiting hours\n",
      "    header: alternative transportation counseling tm 3 hour stanford univ shc employees retirees family members\n",
      "    body_hits: stanford 239 271 318 457 615 642 663 960 966 971\n",
      "    body_hits: aoerc 349 401 432 530 549 578 596\n",
      "    body_hits: pool 521\n",
      "    body_length: 981\n",
      "    pagerank: 1\n",
      "  url: http://events.stanford.edu/2014/February/6/\n",
      "    title: events at stanford thursday february 6 2014\n",
      "    header: stanford university event calendar\n",
      "    header: stanford woods environmental forum featuring roz naylor\n",
      "    header: stanford school of earth sciences alumni reception at nape\n",
      "    header: an evening with stanford alumnus and p\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data_dir = './Data/pa3-data'\n",
    "filename = os.path.join(data_dir, \"pa3.signal.train\")\n",
    "with open(filename, 'r', encoding = 'utf8') as f:\n",
    "    print(f.read()[0:1000])\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vJFdvjxRsHiq"
   },
   "source": [
    "On voit que pour chaque document associé à une requête sont donnés :\n",
    " + son **url** (`url`)\n",
    " + son **titre** (`title`)\n",
    " + un ou plusieurs **headers** (`header`).\n",
    " + un ensemble de **termes d'importance** (`body_hits`) dans le document avec pour chacun de ces termes une liste des positions de chacun de ces termes dans le document.\n",
    " + la **longueur du corps du document** (`body_length`) qui représente le nombre de termes présents dans le corps du document.\n",
    " + un **score de type pagerank** (`pagerank`) qui est un entier entre 0 et 9 qui mesure la qualité du document indépendamment de la requête.\n",
    " \n",
    "D'autres informations comme :\n",
    "+ les **textes d'ancrage** (`anchor_text`) associés à la page et le **nombre d'ancrage** (`stanford_anchor_count`) associé à chaque texte d'ancrage et qui correspond au nombre d'ancrages sur le domaine stanford.edu qui porte ce texte d'ancrage.\n",
    "\n",
    "Par exemple, si le texte d'ancrage est *stanford math department* et que le nombre d'ancrage associé est 9, cela signifie qu'il y a 9 liens vers le document (la page courante) pour lesquels le texte d'ancrage est *stanford math department*.\n",
    "\n",
    "Si vous ne vous rappelez pas ce qu'est un texte d'ancrage, vous pouvez vous reporter au [cours sur le web].\n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oU4_DzpnsHis"
   },
   "source": [
    "#### Accès et récupération des données.\n",
    "\n",
    "Pour faciliter la réalisation de ce TP, plusieurs modules vous sont fournis dans le répertoire `base_classes` de `Utils`. Il y a notamment la fonction `load_train_data` et le module `Query` qui permettent de charger les requêtes du fichier [pa3.signal.train](Data/pa3-data/pa3.signal.train) sous la forme d'un dictionnaire de requêtes comme montré dans le code ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BBKWwjfEsHit"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Récupération de 731 requêtes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from Utils.base_classes.load_train_data import load_train_data\n",
    "from Utils.base_classes.query import Query\n",
    "\n",
    "# Repertoire des données \n",
    "data_dir = './Data/pa3-data'\n",
    "# Nom du fichier\n",
    "file_name = os.path.join(data_dir, \"pa3.signal.train\")\n",
    "# chargement du fichier\n",
    "query_dict = load_train_data(file_name)\n",
    "print(\"Récupération de {0} requêtes\".format(len(query_dict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La code ci-dessous montre un exemple de la récupération de l'information associée à une requête donnée, ici `\"stanford aoerc pool hours\"`sous la forme d'un dictionnaire dont la clé est l'url du document et la valeur un dictionnaire avec l'ensemble des informations associées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'http://events.stanford.edu/2014/February/18/': title: events at stanford tuesday february 18 2014\n",
       "  headers: ['stanford university event calendar', 'teaching sex at stanford', 'rodin the complete stanford collection', 'stanford rec trx suspension training', 'memorial church open visiting hours', 'alternative transportation counseling tm 3 hour stanford univ shc employees retirees family members']\n",
       "  body_hits: {'stanford': [239, 271, 318, 457, 615, 642, 663, 960, 966, 971], 'aoerc': [349, 401, 432, 530, 549, 578, 596], 'pool': [521]}\n",
       "  body_length: 981\n",
       "  pagerank: 1,\n",
       " 'http://events.stanford.edu/2014/February/6/': title: events at stanford thursday february 6 2014\n",
       "  headers: ['stanford university event calendar', 'stanford woods environmental forum featuring roz naylor', 'stanford school of earth sciences alumni reception at nape', 'an evening with stanford alumnus and pandora founder tim westergren 88', 'rodin the complete stanford collection', 'stanford rec trx suspension training', 'memorial church open visiting hours']\n",
       "  body_hits: {'stanford': [248, 327, 371, 418, 514, 653, 796, 817, 1081, 1087, 1092], 'aoerc': [545, 597, 628, 713, 732, 761, 779], 'pool': [704]}\n",
       "  body_length: 1102,\n",
       " 'http://events.stanford.edu/2014/March/13/': title: events at stanford thursday march 13 2014\n",
       "  headers: ['stanford university event calendar', 'rodin the complete stanford collection', 'stanford rec trx suspension training', 'memorial church open visiting hours']\n",
       "  body_hits: {'stanford': [160, 188, 274, 297, 367, 506, 654, 675, 681, 926, 977, 983, 988], 'aoerc': [398, 450, 481, 566, 585, 605], 'pool': [557]}\n",
       "  body_length: 998,\n",
       " 'http://events.stanford.edu/2014/March/3/': title: events at stanford monday march 3 2014\n",
       "  headers: ['stanford university event calendar', 'rodin the complete stanford collection', 'stanford rec trx suspension training', 'memorial church open visiting hours']\n",
       "  body_hits: {'stanford': [188, 196, 331, 375, 514, 674, 1096, 1102, 1107], 'aoerc': [406, 458, 489, 574, 593, 622, 640], 'pool': [565]}\n",
       "  body_length: 1117,\n",
       " 'http://med.stanford.edu/content/dam/sm/hip/documents/FreeFitnessWeek.pdf': title: ffw spring 2017 schedule\n",
       "  body_hits: {'aoerc': [3, 6, 13, 14, 21, 29], 'pool': [11], 'stanford': [125, 135, 264]}\n",
       "  body_length: 352\n",
       "  pagerank: 2,\n",
       " 'http://web.stanford.edu/group/masters/pool.html': title: stanford masters swimming pool & parking information\n",
       "  body_hits: {'pool': [11], 'stanford': [33, 203], 'hours': [131]}\n",
       "  body_length: 212\n",
       "  pagerank: 3\n",
       "  anchors: {'pool & parking info': 13},\n",
       " 'https://alumni.stanford.edu/get/page/perks/PoolAndGyms': title: pool & gyms\n",
       "  headers: ['pool & gyms']\n",
       "  body_hits: {'stanford': [67, 122, 172, 333, 338, 343, 354], 'aoerc': [201], 'hours': [307, 321]}\n",
       "  body_length: 355\n",
       "  pagerank: 4\n",
       "  anchors: {'access to stanford gyms and pools': 1},\n",
       " 'https://cardinalrec.stanford.edu/facilities/aoerc/': title: \n",
       "  pagerank: 4\n",
       "  anchors: {'gyms aoerc': 3, 'aoerc': 13, 'http cardinalrec stanford edu facilities aoerc': 4, 'arrillaga outdoor education and recreation center aoerc link is external': 1, 'the arrillaga outdoor education and research center aoerc': 2, 'aoerc will shutdown for maintenance': 2},\n",
       " 'https://explorecourses.stanford.edu/search?view=catalog&filter-coursestatus-Active=on&page=0&catalog=&q=PE+128%3A+Swimming%3A+Beginning+I&collapse=': title: stanford university explore courses\n",
       "  body_hits: {'stanford': [6, 812], 'pool': [229, 280, 331, 373, 458, 580], 'aoerc': [375]}\n",
       "  body_length: 818\n",
       "  pagerank: 1,\n",
       " 'https://glo.stanford.edu/events/stanford-rec-open-house': title: stanford rec open house graduate life office\n",
       "  headers: ['stanford rec open house']\n",
       "  body_hits: {'stanford': [7, 11, 57, 94, 620, 632, 675, 692, 700, 704, 712, 718, 720], 'aoerc': [46, 193, 204, 268, 279, 319, 330, 397, 464, 475, 522, 533, 574, 611], 'pool': [595, 609]}\n",
       "  body_length: 724\n",
       "  pagerank: 1\n",
       "  anchors: {'stanford rec open house': 3}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Récupération de l'information associée à une requête sous forme d'un dictionnaire de documents\n",
    "query_dict[Query(\"stanford aoerc pool hours\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est alors facile de récupérer le nombre de documents associés à une requête dans cet ensemble d'apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le nombre de documents pour la requête stanford aoerc pool hours est 10\n"
     ]
    }
   ],
   "source": [
    "print(\"Le nombre de documents pour la requête {0} est {1}\".format(\"stanford aoerc pool hours\",len(query_dict[Query(\"stanford aoerc pool hours\")])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut ensuite récupérer un document et les informations sur ce dernier comme montré dans le code ci-dessous.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title: events at stanford tuesday february 18 2014\n",
       " headers: ['stanford university event calendar', 'teaching sex at stanford', 'rodin the complete stanford collection', 'stanford rec trx suspension training', 'memorial church open visiting hours', 'alternative transportation counseling tm 3 hour stanford univ shc employees retirees family members']\n",
       " body_hits: {'stanford': [239, 271, 318, 457, 615, 642, 663, 960, 966, 971], 'aoerc': [349, 401, 432, 530, 549, 578, 596], 'pool': [521]}\n",
       " body_length: 981\n",
       " pagerank: 1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Récupération d'un document\n",
    "sample_doc = query_dict[Query(\"stanford aoerc pool hours\")]['http://events.stanford.edu/2014/February/18/']\n",
    "sample_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document: title: events at stanford tuesday february 18 2014\n",
      " headers: ['stanford university event calendar', 'teaching sex at stanford', 'rodin the complete stanford collection', 'stanford rec trx suspension training', 'memorial church open visiting hours', 'alternative transportation counseling tm 3 hour stanford univ shc employees retirees family members']\n",
      " body_hits: {'stanford': [239, 271, 318, 457, 615, 642, 663, 960, 966, 971], 'aoerc': [349, 401, 432, 530, 549, 578, 596], 'pool': [521]}\n",
      " body_length: 981\n",
      " pagerank: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# affichage du document\n",
    "print(\"document:\", sample_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url http://events.stanford.edu/2014/February/18/\n"
     ]
    }
   ],
   "source": [
    "# affichage du contenu du champ url du document\n",
    "print(\"url\", sample_doc.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headers: ['stanford university event calendar', 'teaching sex at stanford', 'rodin the complete stanford collection', 'stanford rec trx suspension training', 'memorial church open visiting hours', 'alternative transportation counseling tm 3 hour stanford univ shc employees retirees family members']\n"
     ]
    }
   ],
   "source": [
    "# affichage du contenu du champ headers du document\n",
    "print(\"headers:\", sample_doc.headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body_hits: {'stanford': [239, 271, 318, 457, 615, 642, 663, 960, 966, 971], 'aoerc': [349, 401, 432, 530, 549, 578, 596], 'pool': [521]}\n"
     ]
    }
   ],
   "source": [
    "# affichage du contenu du champ body hits  du document\n",
    "print(\"body_hits:\",sample_doc.body_hits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lzuKCLVYsHiw"
   },
   "source": [
    "#### Autres données utiles\n",
    "\n",
    "\n",
    "De même, on dispose dans le répertoire [Data/pa3-data](./Data/pa3-data) de :\n",
    "+ un dictionnaire de termes [`terms.dict`](./Data/pa3-data/terms.dict) qui peut être chargé à l'aide du module `pickle` de python et qui associe à chaque terme un identifiant unique (`term_ID`) et inversement.\n",
    "+ un dictionnaire de documents [`docs.dict`](./Data/pa3-data/docs.dict) qui peut être chargé à l'aide du module `pickle` de python et qui associe à chaque url de document un identifiant unique (`doc_ID`) et inversement.\n",
    "+ un dictionnaire inversé [`BSBI.dict`](./Data/pa3-data/BSBI.dict) qui associe à chaque `term_ID` un triplet qui correspond à `(start_position_in_index_file, number_of_postings_in_list, length_in_bytes_of_postings_list)``.\n",
    "\n",
    "\n",
    "**ATTENTION**, dans notre cas, la seule information utile est le nombre de postings dans la liste qui permet de récupérer la fréquence de documents `df` d'un terme. Cet index a été construit à l'aide de l'algorithme [BSBI](https://nlp.stanford.edu/IR-book/html/htmledition/blocked-sort-based-indexing-1.html) qui permet de gérer l'indexation de collections volumineuses.\n",
    "\n",
    "Le code ci-dessous montre quelques exemples de manipulation de ces différents fichiers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NUoxRcMPsHix"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Terms is 347071\n",
      "Le term ID de radiology est 1\n",
      "Le terme d'ID 1 est radiology\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "from Utils.base_classes.id_map import IdMap\n",
    "import math\n",
    "\n",
    "with open(\"./Data/pa3-data/terms.dict\", 'rb') as f:\n",
    "    terms = pkl.load(f)\n",
    "    total_term_num = len(terms)\n",
    "    print(\"Total Number of Terms is\", total_term_num)\n",
    "\n",
    "print('Le term ID de {0} est {1}'.format(\"radiology\",terms[\"radiology\"]))\n",
    "print(\"Le terme d'ID {0} est {1}\".format(1,terms[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TpDr9WwYsHi0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Docs is 98998\n",
      "Le doc d'ID 1 a pour url 0/3dradiology.stanford.edu_patient_care_Case%2520studies_AVM.html\n",
      "Le doc d'url 1 a pour docID 1\n",
      "Le doc d'ID 3452 a pour url 0/asiahealthpolicy.stanford.edu_news_3140\n"
     ]
    }
   ],
   "source": [
    "with open(\"./Data/pa3-data/docs.dict\", 'rb') as f:\n",
    "    docs = pkl.load(f)\n",
    "    total_doc_num = len(docs)\n",
    "    print(\"Total Number of Docs is\", total_doc_num)\n",
    "    \n",
    "print(\"Le doc d'ID {0} a pour url {1}\".format(1,docs[1]))\n",
    "print(\"Le doc d'url {0} a pour docID {1}\".format(docs[\"0/3dradiology.stanford.edu_patient_care_Case%2520studies_AVM.html\"],docs[\"0/3dradiology.stanford.edu_patient_care_Case%2520studies_AVM.html\"]))\n",
    "print(\"Le doc d'ID {0} a pour url {1}\".format(3452,docs[3452]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupération des informations du dictionnaire inversé `BSBI.dict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "co47d7EIsHi3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pour le terme 1 : (6792, 429, 3432)\n",
      "Le df (document frequency) du terme radiology est 429\n"
     ]
    }
   ],
   "source": [
    "with open('./Data/pa3-data/BSBI.dict', 'rb') as f:\n",
    "    postings_dict, termsID = pkl.load(f)\n",
    "\n",
    "print(\"Pour le terme {0} : {1}\".format(1,postings_dict[1]))\n",
    "print(\"Le df (document frequency) du terme {0} est {1}\".format(terms[1],postings_dict[1][1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WJGvTTRxsHi7"
   },
   "source": [
    "## Exercice 1 : construction d'un dictionnaire idf pour chaque terme\n",
    "\n",
    "L'objectif de cette partie est de **prendre en main le jeu de données** en construisant un dictionnaire `{term: idf}` qui contient pour chaque terme son score `idf` et qui nous sera utile plus tard. \n",
    "\n",
    "\n",
    "Nous rappelons que pour un terme présent dans l'index inversé, on a :\n",
    "$$idf(t) = \\log_{10}\\left(\\frac{N}{df_t}\\right)$$\n",
    "\n",
    "Pour un terme non présent dans l'index inversé, on considère :\n",
    "\n",
    "$$idf(t) = \\log_{10}\\left(\\frac{N}{1.0}\\right)$$\n",
    "\n",
    "avec $N$ le nombre total de documents dans la collection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zXzFNeMksHi9"
   },
   "outputs": [],
   "source": [
    "def build_IDF_dict(terms_dict,BSBI_dict,doc_dict):\n",
    "    IDF_dict={}\n",
    "    # A completer\n",
    "    return  IDF_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MPj9GrDCsHjB"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UAqi2hbrsHjC"
   },
   "source": [
    "## Exercice 2 : approche par point\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sr1OJh-CsHjD"
   },
   "source": [
    "Comme nous l'avons vu en cours, la mise en oeuvre de l'approche par point consiste en :\n",
    "\n",
    "   1. Une première étape dite de **feature engineering** et qui va consister à construire un vecteur représentatif pour chaque paire $x_{i,j} = (q_i,d_j)$ de l'ensemble d'apprentissage. En effet, chaque requête $q_i$ est associée à un ensemble de documents et pour chaque document $d_j$, il s'agira d'extraire un vecteur de caractéristiques caractérisant le couple $x_{i,j}= (q_i,d_j)$.\n",
    "   2. Construire des données d'apprentissage supervisé en associant à chaque paire $x_{i,j}$ un label $y_{i,j}$ qui est le score de pertinence fourni dans le fichier [pa3.rel.train](Data/pa3-data/pa3.rel.train). \n",
    "   3. Apprendre une fonction d'ordonnancement sur l'ensemble d'apprentissage ainsi construit.\n",
    "   4. Evaluer le modèle appris sur les données de validation.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pxQMNJEwsHjE"
   },
   "source": [
    "\n",
    "#### Un problème de regression\n",
    "\n",
    "Le problème d'ordonnancement consiste à apprendre une fonction $f$ telle que $f(x_{i,j})$ soit proche de $y_{i,j}$\n",
    "\n",
    "Nous allons implémenter ici une instance très simple de l'approche par point qui consiste à représenter le problème comme un problème de **regression linéaire**. On va donc considérer une fonction $f$ qui donne un score à chaque paire $x =(q,d)$ selon $f(x) = wx+b$. Il s'agit donc d'apprendre le vecteur de poids ${w}$ et le terme de biais $b$ en minimisant la fonction de perte ci-dessous : \n",
    "\\begin{equation}\n",
    "\\sum_{i=1}^m (f(x_{i})-y_{i})^2\n",
    "\\end{equation}\n",
    "Il s'agit d'un problème de minimisation au sens des moindres carrés ordinaire.\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3Igh1q1YsHjF"
   },
   "source": [
    "### Etape 1 : *feature engineering* - Construction du vecteur représentatif de $x=(q,d)$\n",
    "\n",
    "Nous allons représenter chaque paire (requête,document) comme un vecteur de 5 dimensions où chaque dimension correspond à un des champs du document (url, titre, header, body et anchor) et comme valeur à chaque dimension le score `tf-idf` obtenu comme le produit scalaire de $q \\cdot d_{f}$ avec $q$ le vecteur représentatif de la requête dans l'espace des termes et $d_f$ le vecteur représentatif du champ $f$ du document dans l'espace des termes.\n",
    "\n",
    "Ainsi, si on considère $\\vec{q}$ le vecteur représentatif de la requête et $\\vec{d_f}$ le vecteur représentatif du champ $f$ construit sur l'espace des termes, il s'agit donc ici de construire $\\vec{x}$, vecteur représentatif du couple comme :\n",
    "\n",
    "$$\\vec{x}=\\left(\\begin{array}{c}\n",
    " \\vec{q} \\cdot \\vec{d_{\\textrm{url}}} \\\\\n",
    " \\vec{q} \\cdot \\vec{d_{\\textrm{titre}}} \\\\\n",
    " \\vec{q} \\cdot \\vec{d_{\\textrm{header}}}  \\\\\n",
    " \\vec{q} \\cdot \\vec{d_{\\textrm{body}}} \\\\\n",
    " \\vec{q} \\cdot \\vec{d_{\\textrm{anchor}}} \\\\\n",
    "\\end{array} \\right)$$\n",
    "\n",
    "***\n",
    "\n",
    "#### Représentation de la requête : construction du vecteur requête $ \\vec{q}$.\n",
    "\n",
    "Le vecteur requête sera construit en prenant en compte pour chaque terme :\n",
    "\n",
    " + sa fréquence logarithmique dans la requête.\n",
    " + son idf dans le corpus.\n",
    "\n",
    "On ne fera pas de normalisation.\n",
    " \n",
    "Ainsi, pour un terme $i$ présent dans la requête, son vecteur aura comme composante $i$ pour la requête $q$:\n",
    "\n",
    "$$w_{iq}= (1 + \\log_{10}(tf_{t_i,q})) \\times \\log (\\frac{N}{df_{t_i}})$$\n",
    " \n",
    "Ecrire le code permettant de calculer le vecteur d'une requête donnée.\n",
    "\n",
    "**Attention, on ne s'intéresse ici qu'aux termes de la requête.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i21ICa2LsHjJ"
   },
   "outputs": [],
   "source": [
    "# A compléter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZjZ2npQRsHjX"
   },
   "source": [
    "***\n",
    "\n",
    "#### Représentation du document : construction du vecteur représentatif  de chaque champ de document $\\vec{d_{\\textrm{champ}}}$\n",
    "\n",
    "Vous allez construire une représentation (en prenant uniquement en compte les termes de la requête) pour chaque champ des documents associés à une requête. Pour les champs multiples, on considèrera qu'il forme un seul gros document et on multipliera leur score `tf` par le compteur fourni si besoin (exemple ci-dessous `anchor_count`).\n",
    "\n",
    "Par exemple, pour la requête $[\\text{stanford aoerc pool hours}]^T$ et l'exemple ci-dessous\n",
    "```python\n",
    "  url: https://cardinalrec.stanford.edu/facilities/aoerc/\n",
    "    ...\n",
    "    anchor_text: gyms aoerc\n",
    "      stanford_anchor_count: 3\n",
    "    anchor_text: aoerc\n",
    "      stanford_anchor_count: 13\n",
    "    anchor_text: http cardinalrec stanford edu facilities aoerc\n",
    "      stanford_anchor_count: 4\n",
    "    anchor_text: arrillaga outdoor education and recreation center aoerc link is external\n",
    "      stanford_anchor_count: 1\n",
    "    anchor_text: the arrillaga outdoor education and research center aoerc\n",
    "      stanford_anchor_count: 2\n",
    "    anchor_text: aoerc will shutdown for maintenance\n",
    "      stanford_anchor_count: 2\n",
    "```\n",
    "\n",
    "Le tf de l'<b>anchor</b> sera $[\\text{4 25 0 0}]^T$ car il y a 4 *stanford_anchor_count* pour le terme “stanford” et 25 *stanford_anchor_count* pour le terme “aoerc”.\n",
    "\n",
    "On calculera donc le vecteur associé à chaque champ avec, pour chaque terme présent dans la requête, sa fréquence logarithmique normalisée dans le document soit pour le terme $t_i$ dans le document $d$ et la requête :\n",
    "\n",
    "$$w_{id} = \\frac{1 + \\log_{10}(tf_{id})}{1 + \\log_{10}(moy_{tf_{d}})}$$\n",
    "avec \n",
    "\n",
    "$$\n",
    "moy_{tf_{d}} = \\sum_{i=1}^{V} (\\frac{tf_{id}}{|d|}) \n",
    "$$\n",
    "avec $|d|$ le nombre  de termes du vocabulaire différents dans le document $d$.\n",
    "\n",
    "Ecrire le code permettant de calculer le vecteur associé à chaque champ d'un document donné et pour une requête donnée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-XY281rfsHjY"
   },
   "outputs": [],
   "source": [
    "# A compléter\n",
    "# il est conseillé ici d'écrire un ensemble de fonctions génériques\n",
    "#permettant de calculer cette fréquence normalisée\n",
    "#et d'appliquer ces fonctions à chacun des champs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U4w-iHHgsHjb"
   },
   "source": [
    "***\n",
    "\n",
    "### Représentation du couple (document,requête) : vecteur représentatif  $x=(q,d)$\n",
    "Ecrire une fonction qui pour un couple (document,requête) construit le vecteur de dimension 5 associé comme décrit précedemment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ufRpmAaAsHjd"
   },
   "outputs": [],
   "source": [
    "# A compléter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tLxmoyMnsHjg"
   },
   "source": [
    "***\n",
    "\n",
    "### Etape 2 : entraînement du modèle de régression linéaire \n",
    "\n",
    "Pour cette étape, nous allons nous servir de la bibliothèque [`scikit-learn`](https://scikit-learn.org/stable/) qui est une bibliothèque python dédiée à la fouille de données et à l’apprentissage automatique, développée par une équipe de l'INRIA (l'équipe Parietal de l'INRIA Paris Saclay). La communauté de développement de la bibliothèque est très active et c’est donc une bibliothèque qui évolue souvent et rapidement. Les principaux objets manipulés sont des objets de type array de numpy. C’est une bibliothèque qui possède de nombreuses fonctionnalités et elle est très utile dès lors que l’on souhaite mettre en place des algorithmes d'apprentissage.\n",
    "\n",
    "Il vous faudra d'abord l'installer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tCdL8yFksHjh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (0.22.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from scikit-learn) (0.14.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from scikit-learn) (1.16.4)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from scikit-learn) (1.4.1)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 20.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip3 install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jsx9X-_XsHjk"
   },
   "source": [
    "Nous utiliserons en particulier le module [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression) de cette bibliothèque dont un exemple d'utilisation est disponible [ici](https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html#sphx-glr-auto-examples-linear-model-plot-ols-py) et qui met bien en avant le principe de scikit-learn selon lequel toute approche de regression ou de classification, ici représentée par la variable $clf$, utilise deux fonctions essentielles:\n",
    " + La fonction **clf.fit(data,target)** qui apprend un modèle à partir de données supervisée et le stocke dans la variable $clf$. `data` sont les données d'entrée et `target` les labels.\n",
    " + La fonction **clf.predict(newdata)** qui renvoie un tableau qui stocke, pour chaque nouvelle donnée en entrée, la classe prédite par le modèle appris.\n",
    "\n",
    "Si vous n'avez jamais utilisé cette bibbliothèque, nous vous recommandons de prendre le temps de lire ce rapide tutorial [ici](https://scikit-learn.org/stable/tutorial/basic/tutorial.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Calcul des caractéristiques sur le jeu de données pa3.\n",
    "\n",
    "Nous allons ici mettre en oeuvre cette approche d'apprentissage sur le jeu de données pa3. On entrainera le modèle sur l'ensemble d'apprentissage (`pa3.signal.train` et `pa3.rel.train`) et on le testera sur l'ensemble de test (`pa3.signal.dev` et `pa3.rel.dev`).\n",
    "La première étape consiste donc ici à appliquer l'étape précédente de feature engineering au jeu de données pa3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vIkX3TmEsHjl"
   },
   "outputs": [],
   "source": [
    "# Calculer les caractéristiques et les valeurs de pertinences pour les données d'apprentissage\n",
    "\n",
    "train_signal_file = \"./Data/pa3-data/pa3.signal.train\"\n",
    "train_rel_file = \"./Data/pa3-data/pa3.rel.train\"\n",
    "\n",
    "# A compléter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "#### Entrainement du modèle d'ordonnancement.\n",
    "Il s'agit ici d'apprendre le modèle de regression qui sera utilisé pour l'ordonnancement à l'aide des fonctionnalités de la bibliothèque `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kUqJBCeAsHjo"
   },
   "outputs": [],
   "source": [
    "# Entrainer un modèle de regression linéaire\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "\n",
    "# A completer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "A l'aide de l'étape précédente, vous venez d'apprendre un modèle que vous pouvez maintenant utiliser sur de nouvelles données pour mettre en place un système de recherche d'information.\n",
    "Pour cela, étant donnée une requête $q$ et l'ensemble des documents $(d_1,....d_m)$ qui contiennent des termes de la requête, il suffit d'appliquer le modèle $f$ appris à chaque couple $(q,d_i)$ qui va donc prédire un score de pertinence pour ce couple. Il suffira ensute d'ordonner par ordre de pertinence decroissant pour répondre à la requête.\n",
    "\n",
    "Nous allons maintenant appliquer ce modèle à l'ensemble des données de test, c'est-à-dire les données du fichiers `pa3.signal.dev`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xtftAYmPsHjs"
   },
   "outputs": [],
   "source": [
    "# Calculer les caractéristiques et les valeurs de pertinences pour les données de test\n",
    "\n",
    "dev_signal_file = \"./Data/pa3-data/pa3.signal.dev\"\n",
    "dev_rel_file = \"./Data/pa3-data/pa3.rel.dev\"\n",
    "\n",
    "# a completer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8o92QAwEsHju"
   },
   "outputs": [],
   "source": [
    "# Obtenir les prédictions sur l'ensemble de test\n",
    "\n",
    "# A completer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QDLhBkGFsHjy"
   },
   "source": [
    "***\n",
    "\n",
    "### Etape 3 : évaluation du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Awccz0G2sHjz"
   },
   "source": [
    "Pour terminer ce travail, il est maintenant nécessaire d'évaluer le modèle de recherche ainsi appris. Vous allez ici évaluer votre modèle avec l'erreur quadratique moyenne et avec la mesure NDCG. En effet, comme nous avons des jugements de pertinence non-binaire, la métrique utilisée pour l'évaluation du système de recherche est le NDCG (Normalized Discounted Cumulative Gain). Vous pouvez prendre le temps de regarder le cours sur l'évaluation si vous ne vous rappeler plus de cette mesure.\n",
    "\n",
    "Comme chaque requête a au plus 10 résultats, nous utilisons cette métrique sur les 10 premiers résultats de la recherche.\n",
    "\n",
    "Pour une requête $q$ \n",
    "\n",
    "$$NDCG(q) = \\frac{1}{Z} \\sum_{m=1}^{p}\\frac{2^{R(q,m)}-1}{log_{2}(1+m)}$$\n",
    "Ici, $R(q, m)$ est le jugement de pertinence donné pour le document $m$ et la requête $q$. $Z$ est le facteur de normalisation et correspond à la valeur NDCG idéale que l'on obtient en triant les documents en ordre décroissant de pertinence et en calculant le NDCG  avec $Z=1$. $p$ est le nombre de documents qui sont retournés.\n",
    "\n",
    "Pour un ensemble de requêtes $Q = \\{q_1,...,q_m\\}$ on prend la moyenne des NDCGs de chaque requête. \n",
    "\n",
    "On utilisera pour l'erreur quadratique scikit_learn : documentation [ici](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error) et il vous faudra implémenter la mesure NDCG. Vous pouvez vous inspirer du module [NDCG](./Utils/base_classes/ndcg.py) écrit en orienté objet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IPhJRrYOsHj0"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "# A completer"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Lab6_LearningToRank.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
